## 2.1 

* 启动服务器



## 2.2 

* 查看修改意见
  * 题目“metric”不明确
  * 实验结果中mrr不止在低维效果好，怎么解释
  * 引用指定的文件
* 熟悉实验代码

## 2.3

* 模型代码在187服务器/home/omnisky/hm/exp路径下

* 训练代码

  ```shell
   CUDA_VISIBLE_DEVICES=0 python main.py --dataset FB15k-237 --num_iterations 500 --batch_size 128   --lr 0.0005 --dr 1.0 --edim 200 --rdim 200 --input_dropout 0.3        --hidden_dropout1 0.4 --hidden_dropout2 0.5 --label_smoothing 0.1 --model_name head_project
  ```

* 测试代码

  ```shell
  CUDA_VISIBLE_DEVICES=0 python main.py --dataset FB15k --mode test --model_name head_project --init_checkpoint true --rdim 200
  # 测试代码有分关系测试
  
  CUDA_VISIBLE_DEVICES=0 python test.py --dataset WN18RR --mode test --model_name head_project --init_checkpoint true --rdim 600
  ```

* 

* 论文第二章

* 

## 2.4

* DURA实验结果

  ```
  Evaluation: : 18000ex [00:02, 8146.24ex/s]
  Evaluation: : 18000ex [00:06, 2682.36ex/s]
  Evaluation: : 20500ex [00:02, 7794.45ex/s]
  Evaluation: : 20500ex [00:07, 2633.40ex/s]
  Evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:06<00:00, 8014.66ex/s]
  Evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:14<00:00, 3353.30ex/s]
           TRAIN:  {'MRR': 0.7599307000637054, 'hits@[1,3,10]': tensor([0.6787, 0.8166, 0.9032])}
           VALID:  {'MRR': 0.3767203837633133, 'hits@[1,3,10]': tensor([0.2822, 0.4150, 0.5651])}
  Evaluation: : 20500ex [00:02, 7572.12ex/s]
  Evaluation: : 20500ex [00:07, 2597.57ex/s]
           TEST :  {'MRR': 0.3701469749212265, 'hits@[1,3,10]': tensor([0.2749, 0.4084, 0.5613])}
  ```



* 只采用损失较高的负样本

  ```
  b = torch.topk(negative_score,k=int(args.negative_sample_size/2), largest=False)
  negative_score = b.values
  ```

  * 之前改的代码在kgecl目录下	

## 2.5

* 高损失采样实验结果

  * best config of TransE
  * 论文中结果
    * ![](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20230205145539402.png)

  * 实际结果

    * ```
      
      ```

    
  
  *  修改后实验结果
  
    * ```
      2023-02-05 13:06:26,474 INFO     Valid MR at step 99999: 162.509410
      2023-02-05 13:06:26,474 INFO     Valid HITS@1 at step 99999: 0.239549
      2023-02-05 13:06:26,474 INFO     Valid HITS@3 at step 99999: 0.376704
      2023-02-05 13:06:26,474 INFO     Valid HITS@10 at step 99999: 0.534246
      2023-02-05 13:06:26,474 INFO     Evaluating on Test Dataset...
      2023-02-05 13:06:26,946 INFO     Evaluating the model... (0/2560)
      2023-02-05 13:07:15,195 INFO     Test MRR at step 99999: 0.332123
      2023-02-05 13:07:15,195 INFO     Test MR at step 99999: 172.874719
      2023-02-05 13:07:15,195 INFO     Test HITS@1 at step 99999: 0.233509
      2023-02-05 13:07:15,195 INFO     Test HITS@3 at step 99999: 0.371714
      2023-02-05 13:07:15,195 INFO     Test HITS@10 at step 99999: 0.528047
      ```
  
* 修改提交版论文

* 修改后模型效果提升有限

## 2.6

* 大论文第二章，相关嵌入模型重写，新增度量学习，删除引言
* 第三章将数据集与评估标准合并，新增实验设置
* 当前16266字，47页

## 2.7 

* 读了一篇实体注意负采样文章，有代码，
* 文章名：**Entity Aware Negative Sampling with Auxiliary Loss of False Negative Prediction for Knowledge Graph Embedding**
* 引入高斯分布与auxiliary loss（辅助损失）
* 
* 关系注意负采样
* 师姐大论文1w+6k8+7k1
* 我的8600+3900+1500

## 2.8

* 完成单个关系实验 参考KGE-CL

* 在DURA基础上添加新损失，效果可以调

* ````
  TuckER WN18RR最终训练结果
  Number of data points: 6068
  Hits @10: 0.5121951219512195
  Hits @3: 0.4698417930125247
  Hits @1: 0.43539881344759396
  Mean rank: 6209.889584706658
  Mean reciprocal rank: 0.461735131653968
  Test:
  Number of data points: 6268
  Hits @10: 0.5199425654116145
  Hits @3: 0.47654754307594127
  Hits @1: 0.4361837906828334
  Mean rank: 6127.832322910019
  Mean reciprocal rank: 0.4650587206998672
  3.000673294067383
  
  ````

* 

## 2.9

* 给新代码添加保存、日志模块，
* 完成小论文最终稿
* 度量学习
* 扩展第三章，目前2w字
* 原模型跑出最优结果
* 

## 2.10 

* 基于EANS和KGL-CL定下第四章基本框架：基于关系注意力的负采样+辅助损失

## 2-11

* 错误样例示意图
* 错误案例与关系联系紧密度，如何将这种紧密度转换为采样策略，采样前后关系数量对比
* 为实体关系对设计向量，通过拉远向量与实体相关性提高白羊效果，如何在求导过程中提现
* 高斯分布与伯努利分布异同点分析，如何应用高斯分布

## 2-12

* 完成提交版小论文

* 针对三点审稿意见的修改

  1. 实体度量是何种度量？======在3.1节引言出给出了具体介绍

     ```
     Metric learning aims to learn the distance between data objects from data [9,10], compared with the TDDs using Euclidean distance to translate entities, we believe that learning embedding by measuring semantic similarity between entities can better improve the expression ability of embeddings. Therefore, we propose an embedding method based on entity metric learning, the purpose of our method is to learn the projection matrix M based on relation representation, map the head and tail entities into a specific hyperplane determined by relation, and obtain the final entity and relation representation by reducing the cosine similarity between them.
     ```

  2. 明明是各个维度都表现最好为什么说只有低维表现好？修改为可以从很低的维度开始就有较好的表现

     ```
     具体在摘要和实验处
     Introduce a shared features tensor to reduce the number of parameters while retaining the overall characteristics, which not only makes the model show outstanding performance in both low and high embedding dimensions but also tremendously improved the training efficiency.
     ```

  3. 引用推荐的文献---已引用

     ```
     With the rapid development of representation-based named entity recognition[2,3] and relationship extraction[4,5] technology, more and more researchers have turned their attention to KGE.
     ```

* 大论文致谢

* 20406字

## 2.13

* 提交最终版小论文
* 整理第二个工作
* 补充第一个工作
* 大论文20523字

## 2.14

* 理清第四章脉络
* 对比实验表
* 大论文26086字

## 2-15

* 修改实验代码
* 参考EANS完成新的两张图的绘制，hit@10-nega_sam_size以及MRR-epoch
* 写摘要
* 方法部分添几张图凑页数
* 28237

|      | TransE                                                       |                                                              |      |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---- |
| 4    | Test MRR at step 49999: 0.273838<br/>2023-02-15 16:36:47 INFO     Test MR at step 49999: 268.571167<br/>2023-02-15 16:36:47 INFO     Test HITS@1 at step 49999: 0.188141<br/>2023-02-15 16:36:47 INFO     Test HITS@3 at step 49999: 0.304016<br/>2023-02-15 16:36:47 INFO     Test HITS@10 at step 49999: 0.443198 | Test MRR at step 49999: 0.297934<br/>2023-02-15 15:46:15 INFO     Test MR at step 49999: 189.859792<br/>2023-02-15 15:46:15 INFO     Test HITS@1 at step 49999: 0.211351<br/>2023-02-15 15:46:15 INFO     Test HITS@3 at step 49999: 0.325149<br/>2023-02-15 15:46:15 INFO     Test HITS@10 at step 49999: 0.471953 |      |
| 8    | Test MRR at step 49999: 0.281193<br/>2023-02-15 16:49:13 INFO     Test MR at step 49999: 257.637790<br/>2023-02-15 16:49:13 INFO     Test HITS@1 at step 49999: 0.193541<br/>2023-02-15 16:49:13 INFO     Test HITS@3 at step 49999: 0.313667<br/>2023-02-15 16:49:13 INFO     Test HITS@10 at step 49999: 0.453166 | Test MRR at step 49999: 0.308509<br/>2023-02-15 15:58:49 INFO     Test MR at step 49999: 184.365973<br/>2023-02-15 15:58:49 INFO     Test HITS@1 at step 49999: 0.219193<br/>2023-02-15 15:58:49 INFO     Test HITS@3 at step 49999: 0.338977<br/>2023-02-15 15:58:49 INFO     Test HITS@10 at step 49999: 0.486832 |      |
| 16   | Test MRR at step 49999: 0.286450<br/>2023-02-15 17:01:50 INFO     Test MR at step 49999: 251.863652<br/>2023-02-15 17:01:50 INFO     Test HITS@1 at step 49999: 0.197059<br/>2023-02-15 17:01:50 INFO     Test HITS@3 at step 49999: 0.320580<br/>2023-02-15 17:01:50 INFO     Test HITS@10 at step 49999: 0.462352 | Test MRR at step 49999: 0.315397<br/>2023-02-15 16:11:30 INFO     Test MR at step 49999: 190.777387<br/>2023-02-15 16:11:30 INFO     Test HITS@1 at step 49999: 0.226180<br/>2023-02-15 16:11:30 INFO     Test HITS@3 at step 49999: 0.345671<br/>2023-02-15 16:11:30 INFO     Test HITS@10 at step 49999: 0.493819 |      |
| 32   | Test MRR at step 49999: 0.288932<br/>2023-02-15 17:14:34 INFO     Test MR at step 49999: 252.513584<br/>2023-02-15 17:14:34 INFO     Test HITS@1 at step 49999: 0.198744<br/>2023-02-15 17:14:34 INFO     Test HITS@3 at step 49999: 0.322291<br/>2023-02-15 17:14:34 INFO     Test HITS@10 at step 49999: 0.468509 | INFO     Test MRR at step 49999: 0.316779<br/>2023-02-15 16:24:27 INFO     Test MR at step 49999: 186.359963<br/>2023-02-15 16:24:27 INFO     Test HITS@1 at step 49999: 0.223053<br/>2023-02-15 16:24:27 INFO     Test HITS@3 at step 49999: 0.345964<br/>2023-02-15 16:24:27 INFO     Test HITS@10 at step 49999: 0.496653 |      |

## 2-16

* 29003
* 优化前两张、画图
* ## 

## 2-17

* 优化前两章

* 画图

```.
0.9循环跟1哪个大
两点思索：
1. 0.9循环是否是一个有意义的数，现实生活中是否存在？就像1/3是真实存在的，而0.3循环未必真实存在或者说未必等于1/3,而恰好如果建立在0.3循环=1/3,那么0.9循环=3*1/3=1,这种条件下可以说0.3循环是1/3在十进制下一种妥协后的存在.例如三进制里的小数0.1到了十进制就成了0.3循环，而三进制里的1在十进制就成了0.9循环
2. 比较是否要建立在·确定·的基础上，0.9循环是一个不确定的数，而1是一个确定的数，就像孙悟空参加第一武道会，一会脱下负重带，一会拿出隐藏招数，好像有使不完的劲，而1已经是确定的数了，完整说出自己会什么招数、有多强实力，这样反而是1看似厉害，0.9循环却有使不完的新招数，胜负变得不可知，就是说0.9循环是一个不确定的数
```

* 


## 2-18

* 下问答数据集，跑通实验

* ```
  python3 main.py --mode train --relation_dim 200 --do_batch_norm 1 --gpu 0 --freeze 1 --batch_size 16 --validate_every 10 --hops webqsp_half --lr 0.00002 --entdrop 0.0 --reldrop 0.0 --scoredrop 0.0 --decay 1.0 --model ComplEx --patience 20 --ls 0.05 --l3_reg 0.001 --nb_epochs 200 --outfile half_fbwq
  ```

## 2-19

* 更改采样概率，在所有模型上跑EANS代码作为基线
* 统计实体关系对
* 分关系对比实验选择TransE作为对比模型
* 总结实验结果与代码

## 2-20

* 新增部分2022年参考文献
* 盘完所有实验
* 单个关系实验改用Rotate作为对比模型
* 看审稿意见并总结问题
* 



## 2-21

* 参考宇哥文章添加第三章流程图
* 新加度量函数分析表
* 新加第三章训练流程图
* 新加损失下降曲线
* 添加实验分析
* 继续看审稿意见

## 2-22

* 完善实验结果

* Rotate Wn18Rr 

  |      | MRR      | MR   | 1        | 3        | 10       |
  | ---- | -------- | ---- | -------- | -------- | -------- |
  | 4    | 0.454199 | 6053 | 0.424697 | 0.464742 | 0.511966 |
  | 8    | 0.455620 | 6087 | 0.424856 | 0.468571 | 0.514837 |
  | 16   | 0.460685 | 5869 | 0.429004 | 0.471921 | 0.524888 |
  | 32   | 0.459314 | 5944 | 0.425654 | 0.470964 | 0.525048 |

  

## 2-23

* 重写研究意义
* 使用吉布斯采样

## 2-24

* 看懂吉布斯采样流程
* 将吉布斯采样与当前任务结合
* 总结吉布斯与之前采样的不同并写成方法对比部分
* 

## 2-25 

打一天游戏

吉布斯适合应用在多维数据上

将知识图谱看做三维离散随机变量，应用吉布斯

实体 关系 实体 三个维度的条件概率

关系下的

​	实体1  实体2

实体1

实体2

## 2-26

* 推导理清吉布斯采样

# 2-27

* 将吉布斯与知识图谱采样结合
* 相关技术添加蒙特卡罗方法
* 第一章完成
## 2-28
* 完成第四章实验
* 完善第二章或第三章
