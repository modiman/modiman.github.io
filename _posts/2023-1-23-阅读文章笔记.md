* 问题在于负样本一般是固定的，可能会生成零损失的负样本
* 损害函数的设计策略

* https://kaiyuan.blog.csdn.net/article/details/122264543?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-122264543-blog-128107706.pc_relevant_landingrelevant&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-122264543-blog-128107706.pc_relevant_landingrelevant&utm_relevant_index=5

**几个概念**

* positive example
* random negative 随机负例
* easy  negative 是负例，但对模型的训练效果不大
* hard negative 强负例，对提高模型性能用处很大
* false negative 假负例，即正样本

## 负采样方法分类

### 静态负采样

或者说固定负采样，

* 随机负采样transE等
* 概率负采样RotatE等
* 

### 动态负采样

* 基于GAN的负采样

## 研究动机

1. 当前距离模型大多采用静态（固定）负采样策略，生成的负三元组容易区分，在训练时会出现梯度消失的问题

## 研究思路

1. 梯度消失有没有发生以及怎么发生的？
   1. 实验法：打分变化曲线，梯度变化曲线
   2. 论证法：梯度调整过程
2. 怎么根据梯度消失出现的根本原因设计好的负采样策略
3. **怎么发现更好的负样本**：生成损失高的负样本？选取打分更高的样本作为负例
4. **怎么用发现的负样本优化模型**：怎么把损失与负样本联系起来？基于KGE-CL

### 实验思路

1. 证明选取的负样本是有效的，举例证明，表格展示
2. 证明生成的负样本确实提高了模型性能，链接预测、三元组分类、
3. 



# 基于仿射变换的知识图谱嵌入技术研究与应用

**将问题限定在关系模式上，通过理论和实验证明了提出的方法能建模各种复杂关系模型**

* 基于仿射变换
* 基于距离模型
* 建模6种关系模式
  * 反转
  * 对称
  * 非对称
  * 不可交换组合
  * 可交换组合
  * 多重关系
* 利用路径信息，提出路径正则化
* 利用注意力机制过滤掉无效关系路径
* 基于模型设计的问答模型可以处理多跳问题

## 仿射变换

**行文思路**

1. 举例介绍6种关系模式
2. 介绍线性变换与仿射变换
3. 损失函数
4. 推理证明如何处理六种关系模式
5. 实验设置与结果
6. 实例分析实验结果

## 路径信息

**行文思路**

1. 路径采样
2. 路径向量表示

## 本文分析

**优点**

1. 问题定位明确，从嵌入这个大背景下定位到**建模关系模式**这个小问题
2. 背景讲述详细，能够知道是在解决什么问题
3. 论证详细，通过公式推理逐步证明模型处理每个关系模式的有效性
4. 实验详细，数据集丰富。大实验、消融实验、单个关系实验

**缺点**

1. 模型效果一般，从消融实验和单个的对比试验可以看出模型提升不到一个百分点

**思考**

1. 对于复杂的公式推理审稿人未必详细查看，但无形之中增加了文章的可信度和科学性
2. 详细的问题描述和模型介绍给人一种逻辑清晰的感觉
3. 问答系统不是简单的界面设计，加入数据集以及结合自身模型的实验设计更显专业

# 融合实体邻域信息的知识图谱嵌入负采样方法 

**针对问题**

* 已有的负采样方法多采用均匀随机采样方法构造负样本，这种方式获得的负样本对于模型的训练贡献很小

* 受生成对抗 网络的启发，生成器能够采样更多可信的负三元组，增强嵌入模型性能。

创新点



* 提出一种融合实体邻域信息的知识图谱嵌入负采样方法，

## 实验设计

1. 链接预测实验（效果较好）
2. 具体关系比较
3. 迭代时间
4. 三元组分类实验
5. 负采样效果分析（特色）



# 基于相似性负采样的知识图谱嵌入

````针对现有知识图谱嵌入模型通过从实体集中随机抽取一个实体来生成负例三元组，导致负例三元组质 量较低，影响了实体与关系的特征学习能力。研究了影响负例三元组质量的相关因素，提出了基于实体相似性 负采样的方法来生成高质量的负例三元组。在相似性负采样方法中，首先使用 K-Means 聚类算法将所有实体 划分为多个组，然后从正例三元组中头实体所在的簇中选择一个实体替换头实体，并以类似的方法替换尾实 体。通过将相似性负采样方法与 TransE 相结合得到 TransE-SNS。研究结果表明：TransE-SNS 在链路预测和三 元组分类任务上取得了显著的进步。```

## 实验

实验数据集较老

三元组分类：二分类问题，判断给定的三元组是否为真三元组



# 联合关系上下文负采样的知识图谱嵌入

```首先从原始知识图谱中提取目标实例的邻居并生成上下文向量；然后根据相邻关系 可提供给定实体性质或类型信息的特性，在负采样时利用 Concat 聚合函数对给定实体的关系上下文进行聚合，确定被替换实体的属性；最后结合 TransE 模型的三元组嵌入并选择相同属性的替换实体生成负例三元组，从而提高正负例三元组的相似度。```



```然而，随机采样、过滤采样以及概率采样都是固定采样策略，生成的大多数负例三元组都很容易被区分，导致在训练过程中 会忽略负例三元组分布的变化，存在梯度消失的情况。因此，当对负三元组进行随机采样时，可能会选择到零损失[17]的三元组，阻碍知识图谱嵌入的训练过程，影响知识图谱嵌入获得期望的性能。```



研究思路

找到限制目前模型性能的问题

证明这个问题确实会影响模型

提出一个解决办法

证明这个办法能有效解决提出的问题

证明方法：

1. 公式证明，求导

![image-20230117211946724](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20230117211946724.png)

**逻辑推理**

**![image-20230117212053887](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20230117212053887.png)实验部分

## 常规试验

在

FB15k-237、WN18RR、YAGO-10等数据集上比精度

## 补充实验

### 可视化

1. 可视化单独的实体，选取若干查询（h,r,?）,将其对应的尾实体t的嵌入可视化

![image-20230117212311995](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20230117212311995.png)



2. 可视化实体对应的实体关系对

![image-20230117212407335](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20230117212407335.png)

### 单独实验

1. 对比自己的模型和基线相比单个关系的表现，适用于WN18RR这种关系较少的数据集![image-20230117212507108](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20230117212507108.png)

2. 对关系进行分类，之后进行实验，适合FB15k这种关系比较多的数据集![image-20230117212717347](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20230117212717347.png)![image-20230117212740965](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20230117212740965.png)



## 我的方法

提出基于排名的负例构建

每个mini-batch中的三元组，计算当前所有实体的排名，选择排名前k的实体作为该实体-关系对的负例，计算损失

**FB15k-237**

```
Epoch: 140
	 TRAIN: {'MRR': 0.80372753739357, 'hits@[1,3,10]': tensor([0.7355, 0.8508, 0.9230])}
	 VALID: {'MRR': 0.37218429148197174, 'hits@[1,3,10]': tensor([0.2790, 0.4105, 0.5553])}
Epoch: 145
	 TRAIN: {'MRR': 0.8033256530761719, 'hits@[1,3,10]': tensor([0.7340, 0.8523, 0.9233])}
	 VALID: {'MRR': 0.3710319846868515, 'hits@[1,3,10]': tensor([0.2777, 0.4083, 0.5554])}

```

**WN18RR**

```
	 TRAIN:  {'MRR': 0.9980027675628662, 'hits@[1,3,10]': tensor([0.9966, 0.9994, 1.0000])}
	 VALID:  {'MRR': 0.4965101480484009, 'hits@[1,3,10]': tensor([0.4572, 0.5109, 0.5715])}

Epoch: 115
train loss: 100% 173670/173670 [00:08<00:00, 21095.80ex/s, loss=6.1, reg=4.3]
Evaluation: : 3500ex [00:00, 8736.50ex/s]            
Evaluation: : 3500ex [00:00, 6158.98ex/s]            
Evaluation: : 3500ex [00:00, 8328.25ex/s]            
Evaluation: : 3500ex [00:00, 5601.98ex/s]
Evaluation: 100% 50000/50000 [00:07<00:00, 6763.64ex/s]
Evaluation: 100% 50000/50000 [00:10<00:00, 4774.97ex/s]
	 TRAIN:  {'MRR': 0.998145192861557, 'hits@[1,3,10]': tensor([0.9969, 0.9993, 1.0000])}
	 VALID:  {'MRR': 0.4956643134355545, 'hits@[1,3,10]': tensor([0.4552, 0.5114, 0.5732])}

train loss: 100% 173670/173670 [00:08<00:00, 21249.29ex/s, loss=6.0, reg=4.3]
Epoch: 200
train loss: 100% 173670/173670 [00:08<00:00, 21183.92ex/s, loss=6.0, reg=4.3]
Evaluation: : 3500ex [00:00, 7680.07ex/s]            
Evaluation: : 3500ex [00:00, 4680.51ex/s]            
Evaluation: : 3500ex [00:00, 7553.53ex/s]            
Evaluation: : 3500ex [00:00, 4361.49ex/s]            
Evaluation: 100% 50000/50000 [00:08<00:00, 6089.14ex/s]
Evaluation: 100% 50000/50000 [00:12<00:00, 3909.60ex/s]
	 TRAIN:  {'MRR': 0.9986077845096588, 'hits@[1,3,10]': tensor([0.9976, 0.9995, 1.0000])}
	 VALID:  {'MRR': 0.4967985898256302, 'hits@[1,3,10]': tensor([0.4575, 0.5097, 0.5748])}
Evaluation: : 3500ex [00:00, 6726.04ex/s]            
Evaluation: : 3500ex [00:00, 4221.56ex/s]            
	 TEST :  {'MRR': 0.4980800449848175, 'hits@[1,3,10]': tensor([0.4556, 0.5153, 0.5780])}
```

# 

